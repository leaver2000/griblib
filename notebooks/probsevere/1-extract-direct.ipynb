{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import griblib.probsevere as ps\n",
    "from griblib.probsevere.typed import FeatureCollection\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ps.download2parquet(\n",
    "        Path(\"./probsevere-bucket\"),\n",
    "        start=\"2022-03-01T00:00\",\n",
    "        end=\"2022-03-01T00:02\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "from datetime import datetime\n",
    "from typing import Callable, Union, Iterable, Iterator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from dask.dataframe.core import DataFrame as DaskDataFrame\n",
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "from requests import Session, HTTPError\n",
    "\n",
    "from griblib.probsevere.typed import FeatureCollection\n",
    "\n",
    "PROBSEVERE_URL_TEMPLATE = (\n",
    "    \"https://mtarchive.geol.iastate.edu/%Y/%m/%d/mrms/ncep/ProbSevere/MRMS_PROBSEVERE_%Y%m%d_%H%M00.json\"\n",
    ")\n",
    "\n",
    "\n",
    "TimeLike = Union[datetime, str, pd.Timestamp]\n",
    "\n",
    "\n",
    "def __iterdaterange(\n",
    "    start: TimeLike, end: TimeLike, *, freq: str = \"2min\"\n",
    ") -> Iterator[tuple[pd.Timestamp, pd.DataFrame]]:\n",
    "    dr = pd.date_range(start=start, end=end, freq=freq)\n",
    "    urls = dr.strftime(PROBSEVERE_URL_TEMPLATE)\n",
    "    yield from pd.DataFrame({\"date\": dr, \"urls\": urls}).set_index(dr).groupby(pd.Grouper(key=\"date\", freq=\"D\", axis=0))\n",
    "\n",
    "\n",
    "def __generate_from_features(session: Session, *, urls: Iterable[str]) -> Iterable[pd.DataFrame]:\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # with our session make a get request, r is a response object\n",
    "            r = session.get(url, stream=True)\n",
    "            # in the event of a non 200 status code we'll raise a HTTPError and trigger the except block\n",
    "            r.raise_for_status()\n",
    "        # if there was an error downloading, continue\n",
    "        except (ConnectionError, HTTPError):\n",
    "            warn(f\"error downloading {url}\")\n",
    "            continue\n",
    "        fc: FeatureCollection = r.json()\n",
    "\n",
    "        features = fc[\"features\"]\n",
    "        # in the event no storms were record, continue\n",
    "        if not features:\n",
    "            # warn(f\"url contained no features: {url}\")\n",
    "            continue\n",
    "\n",
    "        df = GeoDataFrame.from_features(features)\n",
    "        # validtime = datetime.strptime(fc[\"validTime\"], \"%Y%m%d_%H%M%S %Z\")\n",
    "        df[\"VALIDTIME\"] = datetime.strptime(fc[\"validTime\"], \"%Y%m%d_%H%M%S %Z\")\n",
    "        yield df\n",
    "\n",
    "\n",
    "def __geometry(\n",
    "    df: GeoDataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    # to keep thins consistent uppercase all of the bounds\n",
    "    df[df.bounds.columns.str.upper()] = df.bounds\n",
    "    point = df.representative_point()\n",
    "    df[\"X\"] = point.x\n",
    "    df[\"Y\"] = point.y\n",
    "    return df\n",
    "\n",
    "\n",
    "def __dtypes(\n",
    "    ddf: DaskDataFrame,\n",
    "    *,\n",
    "    float32_cols: list[str] = [\n",
    "        \"EBSHEAR\",\n",
    "        \"MEANWIND_1-3kmAGL\",\n",
    "        \"MESH\",\n",
    "        \"VIL_DENSITY\",\n",
    "        \"FLASH_DENSITY\",\n",
    "        \"MOTION_EAST\",\n",
    "        \"MOTION_SOUTH\",\n",
    "        \"MAXLLAZ\",\n",
    "        \"P98LLAZ\",\n",
    "        \"P98MLAZ\",\n",
    "        \"WETBULB_0C_HGT\",\n",
    "        \"PWAT\",\n",
    "        \"LJA\",\n",
    "        \"MINX\",\n",
    "        \"MINY\",\n",
    "        \"MAXX\",\n",
    "        \"MAXY\",\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "    ],\n",
    "    int32_cols: list[str] = [\n",
    "        \"MLCIN\",\n",
    "    ],\n",
    "    uint32_cols: list[str] = [\n",
    "        \"MUCAPE\",\n",
    "        \"MLCAPE\",\n",
    "        \"SRH01KM\",\n",
    "        \"FLASH_RATE\",\n",
    "        \"CAPE_M10M30\",\n",
    "        \"SIZE\",\n",
    "        \"ID\",\n",
    "    ],\n",
    "    # 0 - 255\n",
    "    uint8_cols: list[str] = [\n",
    "        \"PS\",\n",
    "    ],\n",
    ") -> DaskDataFrame:\n",
    "\n",
    "    ddf[float32_cols] = ddf[float32_cols].astype(np.float32)\n",
    "    # 32-bit signed integer (``-2_147_483_648`` to ``2_147_483_647``)\n",
    "    ddf[int32_cols] = ddf[int32_cols].astype(np.int32)\n",
    "    # 32-bit unsigned integer (``0`` to ``4_294_967_295``)\n",
    "    ddf[uint32_cols] = ddf[uint32_cols].astype(np.uint32)\n",
    "    # numpy.uint8`: 8-bit unsigned integer (``0`` to ``255``)\n",
    "    ddf[uint8_cols] = ddf[uint8_cols].astype(np.uint8)\n",
    "    return ddf\n",
    "\n",
    "\n",
    "def __to_dask(df: pd.DataFrame, *, chunk_size: int) -> DaskDataFrame:\n",
    "    return dd.from_pandas(df, chunksize=chunk_size).pipe(__dtypes)  # type: ignore\n",
    "\n",
    "\n",
    "def __name_function(time: datetime) -> Callable[[int], str]:\n",
    "    date_string = time.strftime(\"%Y-%m-%d\")\n",
    "    return lambda n: f\"{n}-{date_string}.pq\"\n",
    "\n",
    "\n",
    "def download2parquet(\n",
    "    path: Path,\n",
    "    *,\n",
    "    start: TimeLike,\n",
    "    end: TimeLike,\n",
    "    freq: str = \"2min\",\n",
    "    chunk_size: int = 256,\n",
    ") -> None:\n",
    "    drop_columns = [\"MAXRC_EMISS\", \"MAXRC_ICECF\", \"AVG_BEAM_HGT\", \"geometry\"]\n",
    "    with Session() as session:\n",
    "        for timestamp, values in __iterdaterange(start, end, freq=freq):\n",
    "            # create the inital pandas dataframe\n",
    "            df = (\n",
    "                # download data\n",
    "                pd.concat(__generate_from_features(session, urls=values[\"urls\"]))\n",
    "                # wrangle the geometry\n",
    "                .pipe(__geometry)\n",
    "                .drop(columns=drop_columns)\n",
    "                .pipe(__to_dask, chunk_size=chunk_size)\n",
    "                .to_parquet(  # type: ignore\n",
    "                    path,\n",
    "                    engine=\"pyarrow\",\n",
    "                    append=True,\n",
    "                    name_function=__name_function(timestamp),\n",
    "                    ignore_divisions=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download2parquet(\n",
    "        Path(\"./probsevere-data-new\"),\n",
    "        start=\"2022-03-01T00:00\",\n",
    "        end=\"2022-03-01T00:02\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
