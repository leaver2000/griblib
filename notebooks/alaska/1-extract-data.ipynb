{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import warnings\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from requests import Session, HTTPError\n",
    "\n",
    "\n",
    "HRRR_ALASKA_URL_TEMPLATE = (\n",
    "    \"https://storage.googleapis.com/high-resolution-rapid-refresh/hrrr.%Y%m%d/alaska/hrrr.t00z.wrfnatf%H.ak.grib2\"\n",
    ")\n",
    "TimeLike = Union[datetime, str, pd.Timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grib2 file saved at  /workspaces/griblib/notebooks/alaska/demo/20220720.alaska.t00z.wrfnatf01.ak.grib2\n"
     ]
    }
   ],
   "source": [
    "def download_archive_data(\n",
    "    start: TimeLike,\n",
    "    end: TimeLike,\n",
    "    basedir: Path,\n",
    "    freq: str = \"h\",\n",
    ") -> None:\n",
    "    if not basedir.exists():\n",
    "        basedir.mkdir()\n",
    "    # create a DatetimeIndex using the the function arguments and format the urls using the url template\n",
    "    urls = pd.date_range(start=start, end=end, freq=freq).strftime(HRRR_ALASKA_URL_TEMPLATE)\n",
    "    msg = f\"you are about to atempt to download {len(urls)} grib files, would you like to continue?(y/yes)\"\n",
    "    # adding a user input to verifiy the large download\n",
    "    user_response = input(msg).lower()\n",
    "    if user_response not in (\"yes\", \"y\"):\n",
    "        return None\n",
    "\n",
    "    with Session() as session:\n",
    "        # iterating over all of the urls\n",
    "        for url in urls:\n",
    "            save_to = basedir / \".\".join(url.replace(\"hrrr.\", \"\").split(\"/\")[-3:])\n",
    "            # using a try/catch block in the event the download fails\n",
    "            try:\n",
    "                # make a http get request to the url\n",
    "                r = session.get(url, stream=True)\n",
    "                # on non 200 status code raise HTTPError\n",
    "                r.raise_for_status()\n",
    "                # save the file to the directory\n",
    "                with save_to.open(\"wb\") as fileout:\n",
    "                    shutil.copyfileobj(r.raw, fileout)\n",
    "                print(\"grib2 file saved at \", save_to)\n",
    "\n",
    "            except HTTPError:\n",
    "                warnings.warn(f\"Warning: failed to download {url}\")\n",
    "            # try:\n",
    "            #     # with our session make a get request, r is a response object\n",
    "            #     r = session.get(url, stream=True)\n",
    "            #     # in the event of a non 200 status code we'll raise a HTTPError and trigger the except block\n",
    "            #     r.raise_for_status()\n",
    "            #     # splitting the response.url at each / to get the name of the file and creating a new Path object\n",
    "            #     outfile = basedir / r.url.split(\"/\")[-1]\n",
    "            #     # using the path object in the write mode\n",
    "            #     with outfile.open(\"w\") as f:\n",
    "            #         # and saving the fileout\n",
    "            #         json.dump(r.json(), f, indent=4)\n",
    "\n",
    "            # except (ConnectionError, HTTPError):\n",
    "            #     print(\"error downloading\", url)\n",
    "\n",
    "\n",
    "outdir = Path(\"/workspaces/griblib/notebooks/alaska/demo\")\n",
    "\n",
    "download_archive_data(\n",
    "    start=\"2022-07-20T01:00:00Z\",\n",
    "    end=\"2022-07-20T01:00:00Z\",\n",
    "    basedir=outdir,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
